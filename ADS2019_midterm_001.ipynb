{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADS Midterm 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretic part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (5pts). \n",
    "Imagine traninig a model which considers multiple sattelite images of urban traffic and tries to find groups of typical\n",
    "(repeated with minor deviations) scenarios. How would you classify this problem from Machine Learning perspective?\n",
    "\n",
    "A. Supervised leanring;\n",
    "\n",
    "B. Unsupervised learning;\n",
    "\n",
    "C. Semi-supervised learning;\n",
    "\n",
    "D. Reinforcement learning.\n",
    "\n",
    "Explain you choice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (7pts). \n",
    "Which of the following statements (select all that apply) are true about overfitting problem for linear regression:\n",
    "\n",
    "A. Overfitting problem could be detected by R-squared if the in-sample R-squared\n",
    "is very low.\n",
    "\n",
    "B. Overfitting problem often happens when we do not have enough features but a big\n",
    "number of observations.\n",
    "\n",
    "C. Overfitting problem could be detected by R-squared if the out-of-sample R-\n",
    "squared is very low.\n",
    "\n",
    "D. Overfitting problem could happen when we have many noisy features but a\n",
    "small number of observations.\n",
    "\n",
    "E. Overfitting problem could be detected by R-squared if the out-of-sample R-\n",
    "squared is considerably lower compared to in-sample R-squared.\n",
    "\n",
    "Explain how do you understand the concept of overfitting in general and in the context of your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (8pts). \n",
    "Please explain why would you need separate training, validation and test samples to learn the model. In which cases you may need all three, including a validation sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (10pts). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95%-confidence interval for the linear regression coefficient estimate is [500,1000]. Which of\n",
    "the below can **not** be the 99\\% confidence interval (select all that apply):\n",
    "\n",
    "a) [650 850], b) [0 900], c) [300 1200], d) [300 1100], e) [-1000 -500].\n",
    "\n",
    "Given the 95% interval and the remaining possible choices for the 99\\% confidence interval from above, which of the following p-values could **not** be possible:\n",
    "\n",
    "a) 0.01, b) 0.05, c) 0.1, d) 0.001?\n",
    "\n",
    "Please explain your choice. Note: we need to prove that excluded options are not possible. We do not need to prove the possibility for the remaining options, but need to list all the options which can be proven to be impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# suppress warning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm: FHV Traffic Modeling for Real-Time Autonomous Vehicle Solutions in JFK\n",
    "\n",
    "Transportation network models are essential to transportation operations and planning. A simple yet well-designed linear model can provide us insights on the traffic demand. We are going to model the outgoing traffic around JFK, one of the busiest transportation hubs in NYC. \n",
    "In this test, you'll be asked to:\n",
    "* Find possible correlations from observations\n",
    "* Incoperate time patterns using dummy variables\n",
    "* Run and diagnose linear models, in-sample and out-of-sample. Perform feature selection\n",
    "* Cluster the days based on their ridership patterns to see if we can detect any outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be importing the dataset `JFK60.csv` providing FHV ridership and arrivals at the airport aggregated on the hourly basis:\n",
    "* `fhv`: Number of FHV (For Hired Vehicle) departing from JFK. This is our target variable.\n",
    "* `arrival`: Number of incoming domestic flights arriving JFK, which is assumed to provide a basis for future FHV demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and curate the dataset\n",
    "dataset = pd.read_csv(\"JFK60.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18/1/1 0:00</td>\n",
       "      <td>6</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/1/1 1:00</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18/1/1 2:00</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18/1/1 3:00</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/1/1 4:00</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  arrival  fhv\n",
       "0  18/1/1 0:00        6  263\n",
       "1  18/1/1 1:00        6  138\n",
       "2  18/1/1 2:00        2   50\n",
       "3  18/1/1 3:00        0   24\n",
       "4  18/1/1 4:00        2   45"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the `date` feature into `dt.datetime` format. This is for later creating dummy variables\n",
    "dataset.date = pd.to_datetime(dataset.date, format='%y/%m/%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get day from beginning of the year, hour and day of the week from datetime\n",
    "dataset['hour']=pd.DatetimeIndex(dataset.date).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get day of the week; monday - 0, sunday - 6\n",
    "dataset['dow']=pd.DatetimeIndex(dataset.date).weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get day from beginning of the year\n",
    "dataset['day']=((dataset.date-dt.datetime(2018,1,1))/dt.timedelta(days = 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  arrival  fhv  hour  dow  day\n",
       "0 2018-01-01 00:00:00        6  263     0    0    0\n",
       "1 2018-01-01 01:00:00        6  138     1    0    0\n",
       "2 2018-01-01 02:00:00        2   50     2    0    0\n",
       "3 2018-01-01 03:00:00        0   24     3    0    0\n",
       "4 2018-01-01 04:00:00        2   45     4    0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add time-lagged arrivals (1,2,3,4,5,6 hours before)\n",
    "maxlag = 12\n",
    "lagdata=pd.DataFrame([])\n",
    "for lag in range(1,maxlag+1):\n",
    "        varname = 'lag' + str(lag)\n",
    "        lagdata[varname] = dataset['arrival'].iloc[maxlag-lag:len(dataset)-lag].reset_index(drop = True)\n",
    "datasetL = pd.concat([dataset.loc[maxlag:].reset_index(drop = True), lagdata.reset_index(drop = True)], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>arrival</th>\n",
       "      <th>fhv</th>\n",
       "      <th>hour</th>\n",
       "      <th>dow</th>\n",
       "      <th>day</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>lag3</th>\n",
       "      <th>lag4</th>\n",
       "      <th>lag5</th>\n",
       "      <th>lag6</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>357</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 13:00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>390</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 14:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>606</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 15:00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>601</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 16:00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>676</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  arrival  fhv  hour  dow  day  lag1  lag2  lag3  lag4  \\\n",
       "0 2018-01-01 12:00:00       10  357    12    0    0     7    17    13    11   \n",
       "1 2018-01-01 13:00:00       18  390    13    0    0    10     7    17    13   \n",
       "2 2018-01-01 14:00:00       19  606    14    0    0    18    10     7    17   \n",
       "3 2018-01-01 15:00:00       28  601    15    0    0    19    18    10     7   \n",
       "4 2018-01-01 16:00:00       15  676    16    0    0    28    19    18    10   \n",
       "\n",
       "   lag5  lag6  lag7  lag8  lag9  lag10  lag11  lag12  \n",
       "0    19    11    16     2     0      2      6      6  \n",
       "1    11    19    11    16     2      0      2      6  \n",
       "2    13    11    19    11    16      2      0      2  \n",
       "3    17    13    11    19    11     16      2      0  \n",
       "4     7    17    13    11    19     11     16      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Data Exploration\n",
    "### Q1 (5pts). Print some dataset characteristics: number of records, total number of FHV trips, total number of arriving flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (10pts). Visualize the timeline of FHV rides and arriving flights over the first month (January, 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (5pts). Report correlation between FHV rides and arriving flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Build Linear Regression Model of FHV vs Arrival data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (7pts). Build an OLS model with intercept (you may want to use smf.ols) over `train` using `arrival` as a sole predictor for `fhv` \n",
    "Check p-value for arrival. What does it indicate? Report the 99% confidence interval for arrival's coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (8pts): Consider Historical Impact \n",
    "by adding time lags - add all 12 lag variables into the regression above\n",
    "\n",
    "There is always some delay between passengers arrival and departure (e.g. passing customs, picking up luggage etc). `fhv` might be more related to historical values of flight arrivals (lag) rather than immediate `arrival`. Engineer a formulae with all the following variables and run the regression:\n",
    "* arrival, lag1, ..., lagN: that happens 1hr, ..., N=12 hr ahead.\n",
    "Which of the varialbes have statistically significant impact according to p-values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (5pts): Incorperate Temporal Patterns \n",
    "by adding categorical variables for day of week and hour \n",
    "\n",
    "From the visualization in task1Q3 you may see that both - `fhv` as well as arrivals follow a somewhat periodic temporal pattern. Intuitively, this is true for most traffic flows following daily rhytms including rush hours and also varying over the course of the week. Usually we add dummy/categorical variables (Boolean variable: 1 for True and 0 for False) to encapsulate people's traveling pattern during different time periods.\n",
    "\n",
    "Note that it would not make sense to add hour and dow as regular regressors as we can't anticipate their linear numeric impact. Instead expression `C(.)` could be used in the regression formulae in order to treat those variables as categorical adding corresponding dummy variables to account for their possible discrete values.\n",
    "\n",
    "Perform the regression of fhv agains arrival, lags and temporal categorical variables. Which of the varialbes have statistically significant impact according to p-values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (10pts). Perform feature selection for lag variables\n",
    "As you may see not all the lag variables have statistically signifant impact on the regression. Maybe some of them are not really relevant?\n",
    "Try different amounts of lag variables m=0,1,...,12 using a loop for training the above regression over the training sample, report the out-of-sample R2 over the validation sample and pick up m which maximizes it. Evaluate the final regression over test sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 (10pts). Visualize temporal patterns and lag impacts through bar plots\n",
    "For the best regression above visualize:\n",
    "- bar plot of hour of the day vs its impact coefficient\n",
    "- bar plot of day of the week vs its impact coefficient\n",
    "- bar plot of the lag (0 for immediate arrivals, 1,2,... for lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please find the optimal choice for Lasso regression. What lag feature should we use here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Cluster the days of the year based on the relative timeline of their FHV departures from the airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (8pts). From the entire `dataset`, create a dataframe with days as rows, hours as columns and FHV ridership as values (feel free to use pd.pivottable). Normalize by the total daily ridership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 (12pts). Try K-means with the differet numbers of clusters k=2..7, reporting average Silhuette score for each. Which k is the \"optimal\" from Silhuette's standpoint?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 (15pts). Perform K-means with the optimal k from above. Report the number of occurance of each day of the week within each of the clusters. How would you interpret the clusters based on that? Visualize the aggregated hourly timeline over all the days within each cluster.\n",
    "Create a dictionary of the cluster numbers corresponding to each day of the year, apply it adding a column \"cluster\" to the dataframe and use pivot table with aggregation function `count` to collect the numbers above. Also use pivot table to collect total riders per hour of the day within each cluster for further visualization (after appropriate normalization by the grand total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
